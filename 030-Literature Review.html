<!doctype html>
<html lang="en" data-theme="auto">

<head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc via Lantern" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="css/pico.min.css">
    <link rel="stylesheet" href="css/theme.css">
    <link rel="stylesheet" href="css/theme-switcher.css">
    <link rel="stylesheet" href="css/html.css">
    <link rel="stylesheet" href="css/custom.css">
    <title>The Script has changed - UX in Documentation Portals | </title>

    

    <!-- Loads AnchorJS library: https://www.bryanbraun.com/anchorjs/ -->
    <script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script>

    <!--[if lt IE 9]>
            <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->

    
</head>

<body>
    <div class="theme-switcher">
        <ul>
            <li><a href="#" data-theme-switcher="light">Light</a></li>
            <li><a href="#" data-theme-switcher="dark">Dark</a></li>
        </ul>
    </div>
   
    <h1 class="sr-only">The Script has changed - UX in Documentation Portals</h1>
    
    <main class="container">
        <div class="grid">
            <div class="toc">
                <aside>
                    <nav>
                        <a href="index.html" class="back">
                            Back to Home
                        </a>
                        <ul>                      
                            <li><a href="010-Introduction.html">Introduction</a></li>                      
                            <li><a href="020-Concepts.html">Concepts</a></li>                      
                            <li><a href="030-Literature Review.html"></a></li>                      
                            <li><a href="040-Methods.html">Methods</a></li>                      
                            <li><a href="050-Discussion.html">Discussion</a></li>                      
                            <li><a href="060-Summary and Conclusions.html"></a></li>                      
                            <li><a href="070-Further Research.html"></a></li>                      
                            <li><a href="Appendix A Interviews.html"></a></li>                      
                            <li><a href="Appendix B Relevance Judgement Criteria.html"></a></li>                         
                        </ul>
                        <a href="#top" class="back">
                            Back to Top
                        </a>
                    </nav>
                </aside>
            </div>
            <div class="content" id="#top">
                <h2></h2>
<h2 id="literature-review">Literature Review</h2>
<h3 id="ux-and-technical-writing">UX and Technical Writing</h3>
<p>Technical writing and user experience design overlap. Both are user-centered processes in how they aim to help people to perform tasks. Technical writers and UX designers are users’ advocates in product lifecycle processes.</p>
<p>Ziegler (2022) lists new competencies of technical communicators that emerge due to new technologies. With content delivery portals (which I call documentation portals in this thesis) and dynamic content provisioning gaining ground, the approach to content access has changed and become more situational and user centered. As resulting competencies for technical communicators, Ziegler names among others: defining the sequence of access and retrieval processes, navigation, pre-knowledge, context detection and development of rules to map metadata from component content management systems (CCMS) to search facets in the content delivery portal (CDP).</p>
<p>St.Amant (2022) describes a context-based approach that takes situational variables into account by employing script and prototype theories and shows how this approach can enhance the design thinking approach for technical communicators. St.Amant (2017) also details how prototypes are relevant for user experience design and how these prototypes can vary according to the users’ context. In the present thesis, the relationship of content classes and user experience in documentation portals will be investigated. In such portals, users make sense of navigational elements by reading the labels and expecting a certain concept. This expectation relates to the said prototypes and depends, according to St.Amant, on the user context.</p>
<h4 id="the-viewpoint-when-creating-technical-documentation-and-delivery-processes">The Viewpoint When Creating Technical Documentation and Delivery Processes</h4>
<p>In this section, I will review the current state of technologies used in delivering content to portal applications. I will focus on the point in the respective processes where classification and modularization play a role on content creation or for content delivery to documentation portals.</p>
<p>Documentation portals can provide content dynamically based on target group and context by adapting information selectively to users’ situations and making it accessible (Salwitzek &amp; Steuer, 2020). Typically, content for technical documentation is created in a CCMS and published dynamically to a documentation portal. In the portal users have dynamic access to the content, that is, depending on the context or permission of the user, different content is displayed and can be retrieved. Further elements typically are facetted search, navigation and full-text search (Ziegler, 2020). Additionally, user-based recommendations like related topics can be displayed (Salwitzek &amp; Steuer, 2020).</p>
<p>The above elements for content retrieval can be found in many documentation portals. However, how the functionality is enabled and implemented can vary significantly (Ziegler, 2020).</p>
<p>Content is delivered with the objective to meet a user’s information need in a certain situation. To this end, information must be identifiable and selectable by computer programs. Therefore, information needs to be tagged with classes. The user’s information need can be expressed in user stories, use cases or other process definitions, which translates to a specific delivery case (Ziegler, 2019; Ziegler, 2021; Wilhelm &amp; Ziegler, 2021).</p>
<p>In technical documentation creation there are currently two paradigms around (among others): on the one hand content creation in XML-based CCMS structuring content by assigning metadata, on the other hand graph-based CCMS, where content modules are objects in a knowledge graph. The latter provides many degrees of freedom for content delivery and further application of content as data. However, ontology modelling is often perceived to be costly and complex, and not yet as widely spread as CCMS.</p>
<p>CCMS enable modularized structured content creation to maximize reuse (Oberle &amp; Ziegler, 2012). This is because content follows product complexity, standardization and component-based “mass-customization” of products (Ziegler, 2016). Content in technical documentation is therefore structured in topics, typically in a semantic XML structure that can be standardized or a custom model. Tagging and semantic structuring of the (reusable) topics is applied by technical writers on content creation (Ziegler, 2020; Oeverman &amp; Ziegler, 2016).</p>
<p>The delivery of technical documentation to content delivery portals, on the other hand, can be divided into paradigms based on so-called information or content intelligence levels that lend themself to structure the methods used to leverage content classification in documentation portals.</p>
<p>Ziegler (2019b) describes three levels of content intelligence: native intelligence (content metadata are directly processed on delivery), augmented intelligence (additional semantic layer) and artificial intelligence (automated extraction and processing of metadata using machine learning). Following, I will review relevant research for each level that connects classification of content and user experience in documentation portals.</p>
<p>On the level of native intelligence of information Salwitzek and Steuer (2020) investigate the transformation of CCMS content for delivery in a documentation portal. They use metadata with XSL transformation to, on the one hand, create HTML documents to publish in the portal and to, on the other hand, create a facet file to enable structured search. The XML facet file contains all the metadata used for search (such as filter facets) under the premises that the content has been classified with matching metadata. In other words, using an XSL transformation, one facet can match the exact same metadata in the CCMS or various metadata in the CCMS or match CCMS metadata, but have a different name. With this method, content classes and modules can be leveraged unchanged for search and navigation in the delivery portal, or they can be modified by name change or aggregation according to user needs, for example.</p>
<p>In dynamic content delivery, information can be provided on a granular level. The required context can be delivered in several ways. On the level of augmented information intelligence, one method is the use of microDocs and semantic correlation rules (Ziegler, 2021), where a primary object correlates to secondary objects by selection rules. These selection rules can be seen as a use case.</p>
<p>MicroDocs can bridge the context gap between granular topics and whole document. They can also serve as intermediate maturity level between structured content and knowledge graph representation, although microDocs are not limited to having a graph structure. They can be aggregations of topics from the CCMS delivered as package into the documentation portal. Another option is to assign semantic metadata to content for enhanced retrieval in the portal, leveraging the relations of the semantic layer (Salwitzek &amp; Steuer, 2020).</p>
<p>Burkhardt and Clesle (2020) develop an ontology and a documentation portal without using the content classification at all. They create use cases to model domain knowledge in an ontology on the one hand and to design front end metadata and user interface (UI) on the other hand. The ontology is connected to the front end of the documentation portal using queries. Furthermore, they leverage the ontology to enhance the search experience with synonyms, use case based questions and quick tiles. In the search results, topics are displayed with metadata from the content, such as title, chapter or version. They also provide the possibility to browse the ontology itself to explore the information space.</p>
<p>In technical documentation, retrieval of information that is relevant for specific user needs relies foremost on semantic metadata (Wilhelm &amp; Ziegler, 2021). On the level of artificial intelligence, Wilhelm and Ziegler test IBM Watson for the use of artificial intelligence (AI) in technical communication, comparing a customized model with the generic model for automated content classification, extraction of metadata and knowledge, among others. As one of the steps in the workflow, they describe the creation of a custom metadata taxonomy, a so-called type system, that defines the domain’s entity and relation types for the classification of entities. The hierarchy levels of this taxonomy depend on the required granularity of the information to be tagged for later retrieval.</p>
<p>A typical use case for such automatically tagged content is the search function and the facets in documentation portals, where the indexed entity types and the entities themselves are made searchable for users (Reußner, 2018). In a case when creating a classification semi-automatically, Reußner identifies entities of interest and their aspects based on user group characteristics. He reports to additionally take design aspects of faceted search into account at an early stage of the classification process since faceted search is also a goal of his classification. To enhance the search experience, Reußner furthermore suggests the use of personalized tagging by users. By providing a range of tags to limit the variety, in addition to the possibility to create new tags, such a folksonomy may identify classes that enhance the user experience.</p>
<h4 id="the-viewpoint-of-users-and-cognitive-aspects">The Viewpoint of Users and Cognitive Aspects</h4>
<p>Cognitive mechanisms and theories can relate information seeking to user experience and content properties, such as classification and modularization. Some of the studies I reviewed refer to such cognitive mechanisms. Therefore, I will review research on information foraging theory, relevance theory, relevance judgment and script and prototype theory to analyze possible links between user experience and content classification or modularization in the reviewed studies.</p>
<h3 id="information-foraging">Information Foraging</h3>
<p>Documentation portals are software applications that provide information. They typically integrate a search interface. Users come here to seek information. How users seek information can be explained by employing information foraging and sensemaking theory (Pirolli &amp; Card, 2005). Moreover, this theory can help in designing search interface applications. Information foraging can answer the question “When do people give up the pursued search trail?” Sensemaking can answer the question “What do people need in order to find meaning in a collection of search results?” Information foraging theory draws on optimal foraging theory or how animals decide what to eat (Pirolli &amp; Card, 1999). Information foraging helps users find relevant information. They follow an information scent and decide how long they will follow this information scent on a certain patch by performing a cost/benefit analysis (Russell-Rose &amp; Tate, 2013).</p>
<p>An information scent is the perceived value that information has for satisfying a user’s information needs (Budiu, 2020). The information scent is the stronger, the more of relevant trigger words search results contain (Spool et al., 2004). In a search user interface, information scent can be derived from descriptive titles relevant to the user, highlighted trigger words in the search results and clear labeling of result with relevant categories (Russell-Rose &amp; Tate, 2013). Users perform a cost/benefit analysis on how long to pursue a certain search path. According to the marginal value theorem (Charnov, 1976), there is an expected gain to a search activity in a certain information patch, that is, a search location. After spending time searching and getting returns, the expected within-patch future gain diminishes to a point below the expected gain in another patch (Pirolli &amp; Card, 1999), that is, an easier catch. Users thus make a tradeoff between comprehensiveness and timeliness to save energy on attention (Russell-Rose &amp; Tate, 2013).</p>
<p>Horiguchi et al. (2012) state that a hierarchical menu structure should be designed to be consistent with user expectations and that hierarchical menus should be designed considering syntactic dependency structures. For an instruction manual of a device, they compute information scent of each menu item and of terms representing user tasks. They did this for an organized menu and for a menu with randomized structure, respectively. User tests prove that information scent distribution can predict which item users select as long as they are unfamiliar with the menu design, and that such unlearned users have to base their navigation decision on the lexical similarity between menu labels and their own search intent. Horiguchi et al. (2017) develop a method using a software agent that simulates unlearned users’ navigation decisions following an information scent to predict problematic menu hierarchy.</p>
<h3 id="user-based-approaches-to-classification-of-information">User-based Approaches to Classification of Information</h3>
<p>Hjørland (2013a) critically reviews literature on how effective user-based or cognitive views have been for classification and indexing of information. He concludes that user-based and cognitive approaches cannot contribute to core questions of knowledge organization, such as sorting information units into classes or deciding on synonymy. He acknowledges that user studies were able to provide one learning: A common finding with the introduction of online systems was that searchers preferred textual search. Classes, in contrast, were not considered user-friendly. Hjørland demonstrates how studies of users are not helpful for creating user-friendly knowledge organization, pointing out four issues.</p>
<p>User studies show what is not useful for users, but not how to improve it.</p>
<p>User studies reveal typical information behavior, e.g., avoidance behavior. But certain information or quality of information cannot follow common behavioral trends.</p>
<p>Generalizing user studies that involved information is problematic.</p>
<p>Users’ knowledge is closely connected to the information they are looking for. They cannot be seen as an external factor.</p>
<p>He continues that semantic relations are context-dependent and cannot be deduced by universal cognitive principles. The debate in the reviewed literature was basically discussing if concepts should be studies based on psychological studies or based on cultural and domain-specific studies (Hjørland, 2013a).</p>
<p>Byström (1999) researches how perceived task complexity (work task), information types and source examination relate, and finds that neither task complexity nor the need for multiple information types is related to the increase in external information source use. On the other hand, growing task complexity increases the use of people inside the organization and decreases the use of internal documentary sources. Her first one of the resulting 11 statements is: “As soon as information acquisition requires an effort people as sources are more popular than documentary sources.”</p>
<h3 id="prototypes-in-concept-theory">Prototypes in Concept Theory</h3>
<p>In essence, the above is indicating that finding the right word for the right person is not an easy task. Gabora, Rosch and Aerts (2008) try a context-sensitive approach to concept theory while summarizing the history and current state of concept theory. Concepts help us sort instances into classes or categories, and thereby compare and understand situations. People’s categories form around prototypes that people have. In contrast to concepts, however, prototypes are less demanding in that they need not have defining attributes in common with other category members and boundaries defined. They can be based on experience, culture, goals or any other aspect. Prototypes are very sensitive to context (Gabora et al., 2008).</p>
<h3 id="script-and-prototype-approach-to-context-sensitive-ux">Script and Prototype Approach to Context-Sensitive UX</h3>
<p>A practical approach to this context sensitivity of understanding offers St.Amant (2018) by combining script theory with prototype theory in an adapted form. A script is a type of schema that people’s brains create over time to save processing capacity by summarizing a complex activity into one cognitive unit. The script is tied to a particular setting which needs to be recognized to trigger the script. This is where prototypes of place come into play. People try to match characteristics of the setting to a prototype they have (St.Amant, 2018). This matching is commonly known as expectation. A mismatch is a confusing situation. Based on the script and prototype theory, questions are identified that can guide context-sensitive UX research. These questions relate to items, their characteristics, location and use, presence of other people and their roles, and entry and exit points and conditions of the setting (St.Amant, 2017; St.Amant, 2018), that is, the user context. That the user experience in a certain application such as a documentation portal depends on the user context is relevant for the present research since documentation portals are meant to provide content for several user groups, as the expert interviews will reveal.</p>
<h3 id="relevance-relevance-theory-and-relevance-judgment">Relevance, Relevance Theory and Relevance Judgment</h3>
<p>One of the most important functions of documentation portals is information retrieval (IR) for users. Saracevic (2016) describes relevance as the basic notion underlying all IR systems. Providing relevant information to users according to their queries, profiles and information needs is the objective of any IR system. The principle underlying any classification and categorization and other systems to control information is aboutness, not relevance. It can be organized to fulfil specific needs, but search, in contrast to IR systems, is not an integral part. Relevance, on the other hand, as the underlying notion of search, is a built-in human mechanism that comes with cognition, widely understood by all people. Relevance is created by systems out of queries, algorithms and information. Users derive relevance based on the relation of context and information.</p>
<p>In contrast to the aboutness of classifications, relevance is always a relation. It explains “what makes an input worth picking up from the mass of competing stimuli” (Wilson &amp; Sperber, 2004.)</p>
<p>Relevance theory (Wilson &amp; Sperber, 2004) centers two principles: The Cognitive Principle of Relevance and the Communication Principle of Relevance. In other words, the human mind prioritizes relevance, and assumes the intent of relevance in communication.</p>
<p>Saracevic (2016) analyzes 21 studies that evaluate relevance judgment criteria and finds seven groups with criteria such as topic, quality, depth, type, authority, value in use, confidence (see Appendix B for the list). Another finding was, that people apply multiple criteria interactively and do not infer relevance on topicality alone.</p>
<p>Chu (2011), in a study of relevance judgement factors as part of the 2007 Legal TREC track interactive task of 80 factors, finds specificity, ease of use and subject matter on the first three ranks.</p>
<p>Xu and Chen (2006) in a study measuring five relevance judgement factors find topicality, reliability and understandability on the first three ranks.</p>
<h3 id="the-viewpoint-when-measuring-user-experience-aspects-in-a-documentation-portal">The Viewpoint When Measuring User Experience Aspects in a Documentation Portal</h3>
<p>Following, I will review relevant literature about how operational measurements of user behavior in IR applications involving search and navigational elements correlate with UX aspects. Facets and navigational elements can mirror content classes and modules and the measurements might characterize a relationship between content classes and UX aspects of IR application, which I will detail in the chapter Discussion.</p>
<p>Gwizdka and Spence (2007) ask what searching behavior can tell us about the difficulty of information tasks. They use one single large website for the tasks studied. They correlate operational measures of information search with objective task complexity and subjective post-task difficulty. They find objective path complexity to be determined by factors such as length of navigation path to target information, complexity of navigation choices on each page, information assessment by relevance judgement (target) or information scent (non-target). This to reflect the cognitive effort to seek information. Subjective post-task difficulty is found to be correlated to, for example, time on task and number of pages visited, which is related to number of judgements and navigation decisions to be made and thus to the physical and cognitive effort. A high similarity of users’ navigational path to the optimal path indicates a high efficiency. Users perceive tasks the easier, the higher the search efficiency and the lower the search effort. The perceived task difficulty is found to be correlated to objective task difficulty, but the data suggests that other user-related variables factor in as well, such as cognitive ability, experience, domain knowledge.</p>
<p>Findability is one of the most important qualitative factors in help applications since the volume of technical content is increasing fast. Gao et al. (2020) conduct a findability study in a help center application (Alibaba Cloud). They argue that the unofficial three-click-rule for web design mirrors the impatience of users. Users come with their own queries in mind, so that measuring objective findability, based on conventional precision and recall, is impractical. The objective findability, they describe here, is the system relevance as opposed to the user relevance in Saracevic (2016). The study measures post-task perceived findability and task complexity on a 7-point Likert scale and with user search behavior measures.</p>
<p>Gao et al. (2020) find that since user behavioral data correlates to a large extent with perceived findability, user behavioral data can be used to locate hard-to-find documents in the help center and examine user paths for improvement. Such data are search type and search complexity, number of clicks made to find a target, navigation time, time spent after search, number of search results browsed. The average time spent on each result page correlates only with subjective task complexity.</p>
<p>Bodrunova and Yakunin (2018) assess how user satisfaction is connected to task complexity and perceived menu complexity. They find that the menu complexity has no impact on users’ navigation behavior with tasks of low complexity. In contrast, for high complexity tasks, the perceived menu complexity increases and leads to non-productive search behavior. With high menu complexity users turn to the older menu types not using tag and contextual menu and users’ search behavior lost consistency. The authors find more than two navigational instruments on a page to be counterproductive.</p>
<p>Dorfhuber and Ziegler (2017) investigate how content relevance analysis can provide insights about users of documentation portals and what content they use to find indicators that are relevant to content delivery improvement. One of the indicators was path analysis based on prior content classification as well as the order of navigational elements. They state that content classification can provide for a more precise segmentation for the analysis.</p>
<h3 id="ux-of-facets-and-facets-of-content">UX of Facets and Facets of Content</h3>
<p>A known obstacle to using technical documentation is the vocabulary gap between how a certain user group is able to describe what they search for, and the vocabulary used in the documentation portal. Providing users with pre-defined classes and metadata can mitigate this problem (Reußner, 2018). In search interfaces of applications for dynamic content retrieval, such as in documentation portals, facets typically reflect metadata.</p>
<p>Facet analysis provides a method for creating faceted classes based on users’ interests and the aspects of those interests (Hjørland, 2013b). It seems self-evident that studying and involving users is at the base of user-friendly design. Yet, successful systems like the Google search are not build on user studies. The latter was inspired by bibliometric links between papers (Hjørland, 2013a).</p>
<p>Hearst (2006) finds hierarchical faceted metadata a highly understandable data model for search interfaces. It bridges the complexity between hierarchy and full knowledge representation. He assumes that the user interface for search has as one of its design goals to at all times retain a feeling of control and understanding on the user side, which are typical UX factors. As an example, he mentions the eBay Express interface, where designers determined in advance which facet sets are of most interest for the user. He proves, that the details of the design of search interfaces have a high impact on its success.</p>
<p>Gollub et al. (2019) presents a facet filter method wherein facets broaden the search after a query, in contrast to widely used facets that narrow the search results. The facets are generated from a taxonomy that originates in the metadata of the document set. They test a prototype app versus a baseline system using the UEQ questionnaire. For simple search tasks, the system assessment result was similar. For complex search tasks, however, the new system with the so-called scoped facets scored significantly higher in the user experience questionnaire than the baseline system.</p> 
            </div>
        </div>
    </main>
    

    <script>
        /* pandoc creates two page titles; let's remove the first one */
        page_titles = document.querySelectorAll('h2');
        first = page_titles[0];
        first.remove();

    </script>

    <script>
        /* AnchorJS docs: https://www.bryanbraun.com/anchorjs/ */
        anchors.add();
    </script>

    <script>
        (function() {
            var links = document.getElementsByTagName('a');
            for (var i = 0; i < links.length; i++) {
                if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
                    links[i].target = '_blank';
                }
            }
        })();
    </script>

    <!-- Minimal theme switcher -->
    <script src="js/minimal-theme-switcher.js"></script>

</body>

</html>