# Discussion

I will start with the discussion of the results of my expert interviews. For detailed results see *Appendix A*.

## The Viewpoint of Documentation Portal Software Producers

The interviewees had a heterogeneous view on a possible relationship between content classification and modularization and user experience in documentation portals, as well as on the character of the relationship. Those interviewees, who saw a direct relationship, that is, who linked facets directly to product and content classes, who stated that the module size depends on topics and that technical writers are responsible for context, represented software products that leveraged content and product classes directly into the documentation portal using the respective taxonomies.

When content was delivered using an added layer or semantic technologies, interviewees tended to be less clear about the relationship between content classification and modularization and users and do not connect the user experience directly with content creation. 

Some interviewees indicated that a holistic view of user behavior has an impact on designing user experience. They questioned the benefit of a pull approach with granular information for the user and promoted moderating the content for the user. 

Interviewees all seemed to agree that usability testing is possible only with the content implemented in the documentation portal, which is a strong indicator that content and usability are connected but does not allow conclusions about the role of content classification.

From the expert interviews, I can conclude, that the technology used in content delivery is decisive for content classification and modularization having a direct relationship with UX aspects in documentation portals. In systems that directly leverage content classes and do not aggregate nor split modules, such a relationship exists and makes classification on content creation responsible for some UX aspects. It is currently common to use such systems, however, the majority of the experts represented systems, where such a relationship is indirect or can be bypassed completely, such as ontology-based systems with use case based delivery scenarios.

According to the interviewees, there are documentation portals where the navigational elements directly reflect the classes and modules in the component content management system (CCMS). However, to link the user experience of a documentation portal to the classification and modularization of content, these elements have to be used by users. If they avoid those content-retrieved interaction elements (such as facets) and fall back on full-text search, users might have no direct touchpoints with classification and modularization of content. It seems evident that the mere existence of such navigational aids does not imply a relation between UX aspects and classification or modularization. Hearst [-@Hearst2018] states that the success of a search interface is highly sensitive to the design details and backs this up by examples where design was improved by usability testing, not changing any of the underlying technologies.

Several of the interviewees stated that usability tests of documentation portals are typically not done. However, usability test would be a measure to become aware of users avoiding navigational elements and lead to improve more popular search types, such as full-text query search.

I will continue with a discussion of the reviewed literature about how the conclusions and results interact with each other and how they support, or not, the hypothesis of a relation between UX in documentation portals and classification and modularization of content.

## Relevance Judgement to Identify a Relation Between UX and Content Classification and Modularization

In the chapter *Literature Review*, I retrieved a number of high-ranking relevance judgment criteria [@Saracevic2019, @Chu2011, @XUChen2006]. The reason was that user-perceived relevance appears to be an important factor for successful information retrieval. Various of the factors that influence relevance judgment imply a relationship with classification and modularization of content in documentation portals. Topicality of an information object in a search result list as well as in a document may be represented by tags, for example, of product lifecycle categories such as installation or maintenance, or of a product name. Tags of authors or last-update dates could relate to the factor of reliability affecting relevance judgment. Tags in search result lists and in the content itself oftentimes are generated from content classes. Hence, is a relationship between classification of content and relevance judgment in documentation portals present.

Factors like specificity/amount of information, appropriateness to situation and depth or scope may be related to modularization of content. The smaller the document to be assessed, the less processing effort will be required to judge relevance. The more specific, the easier to identify a good match. An information module with several topics will make it harder to judge if the relevant information is present than one with only one specific topic. Hence, is a relation between modularization and relevance judgement in documentation portals present. Relevance judgment is one of three factors in objective task complexity [@GwizdkaSpence2007]. Objective task complexity correlates with subjective task complexity, the latter being relevant to the user experience in information retrieval systems.

The difficulty with assessing relevance judgment to measure an UX relevant aspect like subjective task complexity in documentation portals is that relevance judgment by users is influenced by many interacting criteria that depend on the user context. Relevance judgment needs to be assessed by people for specific tasks and is hard to measure by analytics software. The sample size would be rather small and, in many cases, not representative for the user base. This makes user relevance judgment as a measurement inefficient. In contrast, system relevance for measuring IR system performance is compared to a previously judged relevance value for a standardized query [@Saracevic2019].

Dorfhuber and Ziegler [-@DorfhuberZiegler2017ContentRelevanceAnalytics] attempt to find out how relevant content is to its users. They suggest path analysis based on prior content classification, and precise content use segmentation for analytics leveraging content classes. This establishes a relationship between classification of content, and the possibility to measure and improve relevant aspects of user experience.

Users find a label the more relevant to their goal, the higher the semantic similarity between menu label and search intent. For users unfamiliar with a specific hierarchical menu, information scent of menu labels can be seen as an UX-relevant parameter in a documentation portal. Information scent can be computed and hierarchical menu labels problematic to usability can be predicted by simulation [@Horiguchi2017]. Menu labels may be directly derived from content classes. In such a case, content classes are linked to the information scent of menu labels and difficulties in navigation can be predicted by simulation.

## Measurements as Characteristic of a Relationship Between UX and Content Classification and Modularization

The work of Gwizdka and Spence [-@GwizdkaSpence2007] suggests that the optimal path length and complexity of navigational choices (link labels, visual design) since they correlate with objective task difficulty, affect the user experience. For IR applications where navigational elements are retrieved from content classes, a relation between content classification and subjective task difficulty can be assumed. However, though subjective task difficulty correlates with objective task difficulty, there seem to be other user-dependent factors influencing subjective task difficulty and thus the user experience.

One finding of the findability study in a help application [@GaoYu2020] is the correlation between the use of several types of search functions (so-called search complexity) and perceived findability. In the Alibaba Cloud Help application those types of search functions (tags, side navigation, content hub) share the same classification and modularization of content. Hence, the UX factor perceived findability in the documentation portal (help center) can be influenced by classification as well as modularization of the content. A prediction model using search complexity and other behavioral measurements could identify hard-to-find documents. However, it does not characterize classification and modularization specifically.

## Facets Make Them Run?

The question if facets and navigational aids are actually useful to users in search comes back in Hjørland [-@Hjorland2013-2] where user studies reveal that searchers prefer textual search. Classes, in contrast, are not considered user-friendly. Also, Byström [-@Bystrom1999] states that people are more popular as sources than documentary sources, and this correlates positively with the amount of information types needed. Bodrunova and Yakunin [-@BodrunovaYakunin2018] explicitly mention a "script" of habitual behavior that searchers seem to fall back on when menu complexity is increased.

In contrast, Hearst [-@Hearst2018], Gollub et al. [-@Gollub2019] and Reußner [-@Reussner201804] and nearly all the interviewed experts find facets in documentation portals to be helpful.

What seems to be a contradiction at first can be explained with relevance theory and script and prototype theory. Users bring the expectation to an application that it provides relevant information for them. Facets that match users' conceptualizations, mental models and situational needs can easily be judged as relevant or not and are perceived as helpful. On the contrary, when there is a vocabulary gap between users and facets or a gap in categorization or other expectations, users perceive facets as confusing.

If facets are leveraged directly from content classification without targeting a use case, then facets are not user-centered, but content-centered, not targeted and only randomly helpful for users.

Script and prototype theory provides a basis to develop methods for a user-centered approach to delivering content, such as the method St.Amant [-@Stamant2022] suggests. Such a method, to be effective for content delivery in documentation portals, should be applied to enhance delivery use cases, which can be different from content creation, depending on the technology used.

## Technologies on Content Delivery and Use Cases

Use cases appear to be the link between content classification and user experience in documentation portals. In the chapter *Literature Review*, technologies on different levels of content intelligence were discussed. On the native level of content intelligence, it is common to leverage the content structure, that is, the classification and modularization of the content directly as search and navigational elements into the documentation portal. However, all three levels provide the possibility to leverage use cases as a base for search and navigational elements.

On the native level, use cases can be implemented in the XSL transformation. On the augmented level, selection rules in semantic correlation layers, or ontologies can be used to reflect use cases. This can be achieved by microDocs, where content is transformed and packaged, or it can be achieved independently of the content by using the content as data layer, to name two examples of the many available possibilities. On the artificial intelligence level, when creating the entity types and their level hierarchy, and when pre-annotating the training material with a certain vocabulary, the decisions made should be based on use cases as they have an impact on users' search experience.
